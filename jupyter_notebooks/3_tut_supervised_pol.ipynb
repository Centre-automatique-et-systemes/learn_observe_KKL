{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "interpreter": {
   "hash": "876800e5f4140bb8c9eb7cb3630e01ad622f0981781552d39a63585948556d04"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip3 install git+https://github.com/Centre-automatique-et-systemes/lena.git gwpy &> /dev/null\n",
    "!pip3 install git+https://github.com/aliutkus/torchinterp1d.git gwpy &> /dev/null"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys ; sys.path.append('../')\n",
    "import torch.optim as optim\n",
    "import seaborn as sb\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from learn_KKL.luenberger_observer import LuenbergerObserver\n",
    "from learn_KKL.system import VanDerPol\n",
    "from learn_KKL.learner import Learner\n",
    "\n",
    "sb.set_style('whitegrid')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Set up the system\n",
    "system = VanDerPol()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Instantiate the observer\n",
    "observer = LuenbergerObserver(dim_x=2, dim_y=1, method='T', wc=1.5)\n",
    "observer.set_dynamics(system)\n",
    "# Generate (x_i, z_i) data by running system backward, then system + observer\n",
    "# forward in time\n",
    "data = observer.generate_data_svl([-2., 2.], 72000)\n",
    "data, val_data = train_test_split(data, test_size=0.3, shuffle=True)\n",
    "\n",
    "# Train the forward transformation using pytorch-lightning and the learner class\n",
    "# Options for training\n",
    "trainer_options={'max_epochs': 15}\n",
    "optimizer_options = {'weight_decay': 1e-8}\n",
    "scheduler_options = {'mode': 'min', 'factor': 0.1, 'patience': 3,\n",
    "                     'threshold': 1e-4, 'verbose': True}\n",
    "stopper = pl.callbacks.early_stopping.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=5e-4, patience=3, verbose=False, mode='min')\n",
    "# Instantiate learner\n",
    "learner_T = Learner(observer=observer, training_data=data,\n",
    "                    validation_data=val_data, method='T', batch_size=10,\n",
    "                    lr=5e-4, optimizer=optim.Adam,\n",
    "                    optimizer_options=optimizer_options,\n",
    "                    scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                    scheduler_options=scheduler_options)\n",
    "# Define logger and checkpointing\n",
    "logger = TensorBoardLogger(save_dir=learner_T.results_folder + '/tb_logs')\n",
    "checkpoint_callback = ModelCheckpoint(monitor='val_loss')\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=[stopper, checkpoint_callback], **trainer_options, logger=logger,\n",
    "    log_every_n_steps=1, check_val_every_n_epoch=3)"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/p3/klrbnh4x1tn5vhmmlnn29t8c0000gn/T/ipykernel_59515/44563975.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# Generate (x_i, z_i) data by running system backward, then system + observer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m# forward in time\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mobserver\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgenerate_data_svl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m2.\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2.\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m72000\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_test_split\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.3\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshuffle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PhD_code/learn_observe_KKL/src/learn_KKL/luenberger_observer.py\u001B[0m in \u001B[0;36mgenerate_data_svl\u001B[0;34m(self, limits, num_samples, k, dt)\u001B[0m\n\u001B[1;32m    523\u001B[0m         \u001B[0mtsim\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0mt_c\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    524\u001B[0m         \u001B[0my_0\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdim_x\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmesh\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 525\u001B[0;31m         \u001B[0mtq_bw\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata_bw\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msimulate_system\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtsim\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0mdt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    526\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    527\u001B[0m         \u001B[0;31m# Simulate forward in time starting from the last point from previous simulation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PhD_code/learn_observe_KKL/src/learn_KKL/luenberger_observer.py\u001B[0m in \u001B[0;36msimulate_system\u001B[0;34m(self, y_0, tsim, dt)\u001B[0m\n\u001B[1;32m    478\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    479\u001B[0m         \u001B[0;31m# Solve\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 480\u001B[0;31m         \u001B[0msol\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0modeint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdydt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtq\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    481\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    482\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mtq\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msol\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PhD_code/learn_observe_KKL/venv/lib/python3.9/site-packages/torchdiffeq/_impl/odeint.py\u001B[0m in \u001B[0;36modeint\u001B[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     76\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mevent_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 77\u001B[0;31m         \u001B[0msolution\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msolver\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mintegrate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     78\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     79\u001B[0m         \u001B[0mevent_t\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msolution\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msolver\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mintegrate_until_event\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PhD_code/learn_observe_KKL/venv/lib/python3.9/site-packages/torchdiffeq/_impl/solvers.py\u001B[0m in \u001B[0;36mintegrate\u001B[0;34m(self, t)\u001B[0m\n\u001B[1;32m     28\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_before_integrate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 30\u001B[0;31m             \u001B[0msolution\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_advance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     31\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0msolution\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PhD_code/learn_observe_KKL/venv/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py\u001B[0m in \u001B[0;36m_advance\u001B[0;34m(self, next_t)\u001B[0m\n\u001B[1;32m    192\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0mnext_t\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrk_state\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mt1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    193\u001B[0m             \u001B[0;32massert\u001B[0m \u001B[0mn_steps\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_num_steps\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'max_num_steps exceeded ({}>={})'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_steps\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_num_steps\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 194\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrk_state\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_adaptive_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrk_state\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    195\u001B[0m             \u001B[0mn_steps\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    196\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0m_interp_evaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrk_state\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minterp_coeff\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrk_state\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mt0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrk_state\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mt1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnext_t\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PhD_code/learn_observe_KKL/venv/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py\u001B[0m in \u001B[0;36m_adaptive_step\u001B[0;34m(self, rk_state)\u001B[0m\n\u001B[1;32m    253\u001B[0m         \u001B[0;31m# trigger both. (i.e. interleaving them would be wrong.)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    254\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 255\u001B[0;31m         \u001B[0my1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my1_error\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mk\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_runge_kutta_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtableau\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtableau\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    256\u001B[0m         \u001B[0;31m# dtypes:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    257\u001B[0m         \u001B[0;31m# y1.dtype == self.y0.dtype\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PhD_code/learn_observe_KKL/venv/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py\u001B[0m in \u001B[0;36m_runge_kutta_step\u001B[0;34m(func, y0, f0, t0, dt, t1, tableau)\u001B[0m\n\u001B[1;32m     83\u001B[0m     \u001B[0my1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0myi\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     84\u001B[0m     \u001B[0mf1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m...\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 85\u001B[0;31m     \u001B[0my1_error\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmatmul\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdt\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mtableau\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mc_error\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     86\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0my1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my1_error\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     87\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# To see logger in tensorboard, copy the following output name_of_folder\n",
    "print(f'Logs stored in {learner_T.results_folder}/tb_logs')\n",
    "# which should be similar to runs/exp_0/tb_logs/\n",
    "# Then type this in terminal:\n",
    "# tensorboard --logdir=name_of_folder --port=8080\n",
    "\n",
    "# Train and save results\n",
    "trainer.fit(learner_T)\n",
    "learner_T.save_results(checkpoint_path=checkpoint_callback.best_model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Train the inverse transformation using pytorch-lightning and the learner class\n",
    "# Options for training\n",
    "trainer_options={'max_epochs': 20}\n",
    "optimizer_options = {'weight_decay': 1e-6}\n",
    "scheduler_options = {'mode': 'min', 'factor': 0.1, 'patience': 3,\n",
    "                     'threshold': 1e-4, 'verbose': True}\n",
    "stopper = pl.callbacks.early_stopping.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=5e-4, patience=3, verbose=False, mode='min')\n",
    "# Instantiate learner\n",
    "# learner_T_star = Learner(T??, data, True, \"T_star\")???  # TODO\n",
    "learner_T_star = Learner(observer=observer, training_data=data,\n",
    "                         validation_data=val_data, method='T_star',\n",
    "                         batch_size=10, lr=1e-3, optimizer=optim.Adam,\n",
    "                         optimizer_options=optimizer_options,\n",
    "                         scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                         scheduler_options=scheduler_options)\n",
    "# Define logger and checkpointing\n",
    "logger = TensorBoardLogger(save_dir=learner_T_star.results_folder + '/tb_logs')\n",
    "checkpoint_callback = ModelCheckpoint(monitor='val_loss')\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=[stopper, checkpoint_callback], **trainer_options, logger=logger,\n",
    "    log_every_n_steps=1, check_val_every_n_epoch=3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# To see logger in tensorboard, copy the following output name_of_folder\n",
    "print(f'Logs stored in {learner_T_star.results_folder}/tb_logs')\n",
    "# which should be similar to runs/exp_0/tb_logs/\n",
    "# Then type this in terminal:\n",
    "# tensorboard --logdir=name_of_folder --port=8080\n",
    "\n",
    "# Train and save results\n",
    "trainer.fit(learner_T_star)\n",
    "learner_T_star.save_results(checkpoint_path=checkpoint_callback.best_model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Simulate one test trajectory\n",
    "import torch\n",
    "tsim = (0, 60)\n",
    "dt = 1e-2\n",
    "tq, simulation = system.simulate(torch.tensor([[0.5], [0.5]]), tsim, dt)\n",
    "measurement = observer.h(\n",
    "        simulation[:, :observer.dim_x, 0].T).T\n",
    "y = torch.cat((tq.unsqueeze(1), measurement), dim=1)\n",
    "\n",
    "# Predict from measurment\n",
    "estimation = observer.predict(y, tsim, dt)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot ground truth and state estimation\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(simulation.shape[1]):\n",
    "        plt.plot(tq, simulation[:, i, 0], label=rf'$x_{i+1}$')\n",
    "        plt.plot(tq, estimation[:, i].detach().numpy(),\n",
    "                 label=rf'$\\hat{{x}}_{i+1}$')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}